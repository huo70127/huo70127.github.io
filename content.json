{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/12/02/hello-world/"},{"title":"I/O多路复用的一点理解","text":"写这个是因为一个关于Redis为什么这么快的答案中，其中一个原因，就是Redis使用了I/O多路复用模型。于是我回想起一个我觉得很魔幻的经历，就是在2年前换工作时，连续在三场面试中被问到了I/O多路复用，select、poll、epoll的问题。关于为什么一群写业务的工程师都痴迷于这个问题依然是个谜，不过很显然，除非你能打死他们，要不就只能选择加入。 首先先把这个词拆开看，I/O是指网络I/O；多路，是指多个TCP链接或者channel，当发生多个网络请求时，I/O多路就产生了。而复用，是指复用一个或少量线程，比如单进程的Redis，所有的请求都需要复用一个进程。所以这个词串起来理解就是：很多个网络I/O复用一个或少量的线程来处理这些连接。它还有个别称，叫“事件驱动”，就和字面意思一样，就是需要动的时候有人叫你，不叫你的时候你就躺着就行。  目前支持多路复用的系统调用有select、poll、epoll。 select 监视多个文件句柄的状态变化，程序会阻塞在select处等待，直到有文件描述符就绪或超时。 1int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout) 可以看出select可以监听fd_set *readfds, fd_set *writefds, fd_set *exceptfds三种描述符。 缺点： 每次调用select，都需要把待监控的fd集合从用户态拷贝到内核态，当fd很大时，开销很大。 每次调用select，都需要轮询一遍所有的fd，查看就绪状态。 select支持的最大文件描述符（fd）数量有限，默认是1024。 poll 和select没有很大区别，改进成了基于链表的，所以没有最大fd数量限制。 12345678int poll(struct pollfd *fds, nfds_t nfds, int timeout)//pollfd结构包括了events(要监听的事件)和revents(实际发生的事件)。而且也需要在函数返回后遍历pollfd来获取就绪的描述符。struct pollfd{ short events; short revents;}; epoll 针对上面两位的共同缺点做了改进，select 和 poll 监听文件描述符list，进行一个线性的查找 O(n)；epoll 使用了内核文件级别的回调机制O(1)；于是epoll模型在处理大量fd的时候，就和之前的模型有了数量级上的进步。看看这张图，epoll本身几乎是不受并发数的影响的。 /proc/sys/fs/epoll/max_user_watches这个文件表示用户能注册到epoll实例总最大fd的数量，我随便找了台服务器看了眼，790999，貌似够大了。所以在Linux平台，需要并发的场景下，epoll应该已经代替了select和poll。 那么问题来了，既然这么好用的东西出现了，select和poll还用在哪里呢？我想到了以下两个： 管理少量连接（比如fd数 &lt; 10），poll/select 是比较轻量级的，不需要去创建一个epoll的fd。而且，select实现起来应该比epoll简单不少。 编写跨平台代码，保证代码任意平台都能用，那么 cygwin 下只有 poll 给你，win32下对应 select。","link":"/2020/12/02/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3/"},{"title":"","text":"场景：一张数据亿级别的排期表，需要每天清理一年前排期，每次清理一天的，大概50-100w，400M左右。 如果直接delete，根据经验，会造成数分钟甚至更长的主从延迟。说句题外话，在主库写入频繁的业务，高峰时间出现主从延迟是正常的，短的几秒，长的在10分钟以内，都是正常情况，需要读库的业务应该自行保证，当延迟发生是不会严重影响业务运行，比如主从延迟造成页面显示有问题，这个是可以接受的。但是主从延迟造成结算有问题，那就是应该避免的了，敏感数据需要指定去读主库。 那么，为什么delete操作会可能导致主从延迟？ mysql上的delete语句首先会同步到各个从库； delete语句会产生redo日志也会同步在各个从库；delete的时候，redo必须包含对应的insert语句（所有字段），所以产生的日志量可能更大。 mysql本身数据的binlog也在同步； 这个过程中，redo日志传输产生的网络I/O，CPU消耗，磁盘I/O等，加起来就会造成主从延迟。 我们面临的这个场景是删除数据量只是表数据量的一小部分，并且没有删除速度要求。所以比较简单的一种办法： 确定需要删除的数据范围，最好可以使用索引查出来。 DELETE FROM TABLE WHERE *** LIMIT 10000; sleep(1); 类似这样循环删除，并且观察监控，如果引发比较严重的主从延迟就暂停脚本，调整一次删除条数和间隔时间。 这个不是一个完美的方案，如果数据量过大，删除时间可能会很长。在一些公司提供的工具中，也可能不方便使用高级语言或者存储过程。暂时也没找到完美的办法，很多办法需要停服去处理，这个在互联网公司经常是不能接受的。所以，在建表的时候最好能考虑到这种需求，建分区表，便于后期的数据备份和清理。","link":"/2020/12/02/%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AEdelete/"}],"tags":[],"categories":[]}